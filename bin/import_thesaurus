#!/usr/bin/python3
# Read inscriptions from wiki dump and generate Elm module
#
# Import is based on two sources:
#
# 1. A wiki dump XML where we look for articles with a metastring starting
#    with "{{inscription"
# 2. A list that maps token names to unicode tokens
#
# From these sources an Elm module is generated that includes all inscriptions
# with the text of the inscriptions mapped according to the mapping list.
#
# Synopsis:
#    import_thesaurus MODULE_NAME XML_DUMP TOKEN_LIST
#
# Params:
#    MODULE_NAME    Name of the generated Elm module
#    XML_DUMP Wiki  Dump file to search inscriptions in
#    TOKEN_LIST     File with list of token names
#
# Example:
#
#    import_thesaurus \
#       RaeticInscriptions raeticarum/univieacat_raetica-20200210-current.xml \
#       raetic.txt \

#       > src/Imported/RaeticInscriptions.elm

import sys
import os
import re
import html
import xml.etree.ElementTree as ET

from lib.tokens import Token, Types

def escape(str):
    """ I believe string literals in Elm have only the
    backslash and double quote as special chars.
    Prove me wrong. """
    return str.replace("\\", "\\\\").replace("\"", "\\\"")


class Inscription:
    """
    Represent Raeticarum Wiki entries.
    """

    reading_original_pattern = re.compile("\|reading_original=(.*)\n")

    # Tokens are encoded as "{{NAME[|SPEC_NAME]}}" but there are also
    # special markers [, ], and ?
    charlist_pattern = re.compile("\{\{c\|([^}]+)}}|([][?])|(<br>)")
    direction_pattern = re.compile("\|direction=(.*)\n")
    script_pattern = re.compile("\|script=(.*)\n")
    alphabet_pattern = re.compile("\|alphabet=(.*)\n")

    @classmethod
    def from_page(cls, id, source, lookup):
        """
        Read inscription entry from wiki source.

        Params:
            id: Unique ID of the script
            source: Wiki source entry text.
            types: token lookup based on names

        Example of an inscription string from source:

            {{inscription
            |reading=)nuale!?&#93;n&#x0323;uale ri?ienalse!ri?ienals&#x0323;e&#x0323;
            |reading_original={{c|E}}{{c|S||d}}{{c|L}}{{c|A|A14}}{{c|N}}{{c|E}}{{c|I}}?{{c|I}}{{c|R|R2}}{{c|E}}{{c|L}}{{c|A|A14}}{{c|U}}{{c|N}}&#91;
            |direction=sinistroverse
            |letter_height_min=7
            |letter_height_max=11.5 cm
            |letter_number_min=15
            |line_number=1
            |script=North Italic script
            |alphabet=Magrè alphabet
            |language=Raetic
            |meaning=unknown
            |object=AK-1 rock
            |position=left
            |orientation=90
            |craftsmanship=engraved
            |condition=damaged
            |type_inscription=prob. votive
            |date=unknown
            |checklevel=0
            |disambiguation=AK-1
            }}

        The fields we are interested in are:

        - reading_original: Contains the inscription text
        - direction: contains the reading direction
        """

        if not source:
            raise ValueError("No text.")

        if not source.startswith("{{inscription"):
            raise ValueError("Not an inscription.")

        reading_original = cls.reading_original_pattern.search(source).group(1)
        if not reading_original:
            raise ValueError("No field `reading_original`.")

        # The text includes marker signs which are HTML-encoded
        # Example: &#91 -> [
        reading_decoded = html.unescape(reading_original)

        # Split into individual characters.
        char_strings = [ max(res) for res in
                         cls.charlist_pattern.findall(reading_decoded) ]

        direction = cls.direction_pattern.search(source).group(1)

        if direction == "sinistroverse":
            dir = "RTL"
        else:
            dir = "LTR"

        tokens = []
        for char_string in char_strings:
            # There are often two token names, the latter being more specific
            # Example: ["H", "H3"]
            # We want to search for the more specific first.
            names = list(reversed(char_string.split("|")))
            try:
                tokens.append(lookup.closest(names, dir))
            except KeyError:
                # Signs that cannot be mapped are copied over verbatim
                name = names[0]
                if len(name) > 1:
                    tokens.append("<" + name + ">")
                else:
                    tokens.append(name)

        if dir == "LTR":
            text = "".join(tokens)
        else:
            # The text is entered reversed in the wiki to give
            # the desired visual appearance. Undo that by reversing the tokens.
            def split_by_line(tokens):
                line = []
                for t in tokens:
                    if t == "\n":
                        yield line
                        line = []
                    else:
                        line.append(t)
                if line:
                    yield line
            lines = ["".join(reversed(l)) for l in split_by_line(tokens)]
            text = "\n".join(lines)

        script = cls.script_pattern.search(source).group(1)

        alphabet_match = cls.alphabet_pattern.search(source)
        if alphabet_match:
            alphabet = alphabet_match.group(1)
        else:
            alphabet = "Unknown"

        # Take the first three letters of the alphabet name
        # for a short group name.
        group = alphabet[0:3]

        return cls(id, group, dir, text, script)

    def __init__(self, id, group, dir, text, script):
        self.id = id
        self.group = group
        self.dir = dir
        self.text = text
        self.script = script

    def elm_record(self, url_base):
        return """{{ id = "{}", group = "{}", dir = {}, plate = Nothing, text = \"\"\"{}\"\"\", link = Just "{}" }}""".format(
            escape(self.id),
            escape(self.group),
            self.dir,
            escape(self.text),
            escape(url_base + self.id)
        )

    def __lt__(self, other):
        '''
        sorts in human order on the token id
        '''
        return self._sort_words() < other._sort_words()

    def _sort_words(self):
        def atoi(text):
            return int(text) if text.isdigit() else text

        return [ atoi(c) for c in re.split(r'(\d+)', self.id) ]



module_name = sys.argv[1]
dump_file = sys.argv[2]
script_file = sys.argv[3]

with open(script_file) as script_lines:
    tokens = list(Token.from_lines(script_lines))

types = Types(tokens)

# Special chars used in the wiki
types.add(Token('', '[', 'frag', '', 'ambi'))
types.add(Token('', ']', 'frag', '', 'ambi'))
types.add(Token('', '?', 'guess', '', 'ambi'))
types.add(Token(' ', 'space', 'space', '', 'ambi'))
types.add(Token('', 'punctuation1', 'punctuation', '', 'ambi'))
types.add(Token('', 'punctuation2', 'punctuation', '', 'ambi'))
types.add(Token('', 'punctuation3', 'punctuation', '', 'ambi'))
types.add(Token('', 'punctuation4', 'punctuation', '', 'ambi'))
types.add(Token('', 'punctuation5', 'punctuation', '', 'ambi'))
types.add(Token("\n", '<br>', 'br', '', 'ambi'))

# Chars having different names
types.add(Token('', 'Ś', 'Ś', '', 'ambi'))
types.add(Token('', 'Ś2', 'Ś', '', 'ambi'))
types.add(Token('', 'Ś3', 'Ś', '', 'ambi'))
types.add(Token('', 'Χ1', 'Χ', '', 'ambi'))
types.add(Token('', 'Χ2', 'Χ', '', 'ambi'))
types.add(Token('', 'Χ3', 'Χ', '', 'ambi'))
types.add(Token('', '1d', '1d', '', 'ambi'))
types.add(Token('', '10d', '10d', '', 'ambi'))

# Classes of chars we turn into wildcard chars because we don't
# have the sign.
prefix_map = {
    'line': "",
    'symbol': "",
    'add': "",
}

lookup = types.lookup(prefix_map)

inscriptions = []
tree = ET.parse(dump_file)
root = tree.getroot()
xmlns = re.search(r"\{.*\}", root.tag).group()
base_url = os.path.dirname(root.find(f"*/{xmlns}base").text) + '/'

for page_elm in root.findall(f".//{xmlns}page"):
    title = page_elm.find(f"{xmlns}title").text
    text = page_elm.find(f".//{xmlns}text").text
    try:
        inscription = Inscription.from_page(title, text, lookup)

        # There are three entries in latin script in the corpus, ignore those
        if inscription.script != "Latin script":
            inscriptions.append(inscription)

    except ValueError as e:
        pass



inscriptions.sort()


joined_inscriptions = "\n ,".join((i.elm_record(base_url) for i in inscriptions))

print(f"module {module_name} exposing (inscriptions)\nimport WritingDirections exposing (..)\ninscriptions =\n [{joined_inscriptions}\n ]\n")